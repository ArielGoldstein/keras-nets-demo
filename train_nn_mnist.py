"""
Train nets on the MNIST.
"""
from data_loader import load_mnist
from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint
from models import get_mnist_net
import os
import numpy as np
# import resnet

# log_root = '/tigress/qlu/logs/keras-resnet/log'
log_root = 'log'

model_name = 'std'

data_name = 'mnist'
batch_size = 32
n_epochs = 20

# n_subjs = 10
# for subj_id in range(n_subjs):
subj_id = 0
# create various callbacks
log_dir = os.path.join(log_root, data_name, model_name, 'subj%.2d' % (subj_id))
print(log_dir)
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# callbacks
lr_reducer = ReduceLROnPlateau(
    factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=1e-5)
csv_logger = CSVLogger(os.path.join(log_dir, 'history.csv'))
checkpointer = ModelCheckpoint(
    filepath=os.path.join(log_dir, 'weights.{epoch:03d}.hdf5'),
    verbose=1, save_best_only=False, period=1)

# load data
X_train, X_test, Y_train, Y_test, y_train, y_test, data_info = load_mnist(
    model_name)
[n_classes, img_rows, img_cols, img_channels] = data_info
input_shape = (img_rows, img_cols, img_channels)
# get the model
model = get_mnist_net(model_name, input_shape)

# save the random weights
model.save_weights(os.path.join(log_dir, 'weights.%.3d.hdf5' % (0)))

# Fit the model on the batches generated by datagen.flow().
model.fit(X_train, Y_train,
          shuffle=True,
          batch_size=batch_size,
          validation_data=(X_test, Y_test),
          epochs=n_epochs, verbose=2,
          callbacks=[lr_reducer, csv_logger, checkpointer])
